[2025-02-27T10:50:25.133+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T10:50:25.148+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T10:50:25.148+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T10:50:25.161+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T10:50:25.165+0000] {standard_task_runner.py:57} INFO - Started process 182 to run task
[2025-02-27T10:50:25.174+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmprgky4qm9']
[2025-02-27T10:50:25.179+0000] {standard_task_runner.py:85} INFO - Job 5: Subtask create_station_informations_table
[2025-02-27T10:50:25.335+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 5869344327a9
[2025-02-27T10:50:25.486+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T10:50:25.488+0000] {sql.py:262} INFO - Executing: 
            CREATE TABLE IF NOT EXISTS velib_station_details (
            station_id BIGINT PRIMARY KEY, 
            capacity INT,                   
            lat DOUBLE PRECISION,          
            lon DOUBLE PRECISION,           
            name VARCHAR(255)               
        );
        
[2025-02-27T10:50:25.496+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T10:50:25.642+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T10:50:25.648+0000] {sql.py:375} INFO - Running statement: 
            CREATE TABLE IF NOT EXISTS velib_station_details (
            station_id BIGINT PRIMARY KEY, 
            capacity INT,                   
            lat DOUBLE PRECISION,          
            lon DOUBLE PRECISION,           
            name VARCHAR(255)               
        );
        , parameters: None
[2025-02-27T10:50:25.653+0000] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/operators/sql.py", line 274, in execute
    **extra_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 349, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 380, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.

[2025-02-27T10:50:25.661+0000] {taskinstance.py:1373} INFO - Marking task as FAILED. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T105025, end_date=20250227T105025
[2025-02-27T10:50:25.671+0000] {standard_task_runner.py:109} ERROR - Failed to execute job 5 for task create_station_informations_table (duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
; 182)
[2025-02-27T10:50:25.686+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 1
[2025-02-27T10:50:25.709+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T10:59:31.196+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T10:59:31.205+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T10:59:31.205+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T10:59:31.214+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T10:59:31.222+0000] {standard_task_runner.py:57} INFO - Started process 182 to run task
[2025-02-27T10:59:31.223+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpc6wdjeb6']
[2025-02-27T10:59:31.230+0000] {standard_task_runner.py:85} INFO - Job 3: Subtask create_station_informations_table
[2025-02-27T10:59:31.350+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 3d206dcce365
[2025-02-27T10:59:31.481+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T10:59:31.481+0000] {sql.py:262} INFO - Executing: 
            CREATE TABLE IF NOT EXISTS velib_station_details (
            station_id BIGINT PRIMARY KEY, 
            capacity INT,                   
            lat DOUBLE PRECISION,          
            lon DOUBLE PRECISION,           
            name VARCHAR(255)               
        );
        
[2025-02-27T10:59:31.491+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T10:59:31.633+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T10:59:31.638+0000] {sql.py:375} INFO - Running statement: 
            CREATE TABLE IF NOT EXISTS velib_station_details (
            station_id BIGINT PRIMARY KEY, 
            capacity INT,                   
            lat DOUBLE PRECISION,          
            lon DOUBLE PRECISION,           
            name VARCHAR(255)               
        );
        , parameters: None
[2025-02-27T10:59:31.645+0000] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/operators/sql.py", line 274, in execute
    **extra_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 349, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 380, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.

[2025-02-27T10:59:31.652+0000] {taskinstance.py:1373} INFO - Marking task as FAILED. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T105931, end_date=20250227T105931
[2025-02-27T10:59:31.665+0000] {standard_task_runner.py:109} ERROR - Failed to execute job 3 for task create_station_informations_table (duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
; 182)
[2025-02-27T10:59:31.701+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 1
[2025-02-27T10:59:31.748+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T11:13:55.370+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T11:13:55.378+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T11:13:55.379+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T11:13:55.390+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T11:13:55.393+0000] {standard_task_runner.py:57} INFO - Started process 224 to run task
[2025-02-27T11:13:55.396+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp6h7immrp']
[2025-02-27T11:13:55.398+0000] {standard_task_runner.py:85} INFO - Job 3: Subtask create_station_informations_table
[2025-02-27T11:13:55.463+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 4e453fff3cdd
[2025-02-27T11:13:55.545+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T11:13:55.546+0000] {sql.py:262} INFO - Executing: 
            CREATE TABLE IF NOT EXISTS velib_station_details (
            station_id BIGINT PRIMARY KEY, 
            capacity INT,                   
            lat DOUBLE PRECISION,          
            lon DOUBLE PRECISION,           
            name VARCHAR(255)               
        );
        
[2025-02-27T11:13:55.556+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T11:13:55.695+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T11:13:55.700+0000] {sql.py:375} INFO - Running statement: 
            CREATE TABLE IF NOT EXISTS velib_station_details (
            station_id BIGINT PRIMARY KEY, 
            capacity INT,                   
            lat DOUBLE PRECISION,          
            lon DOUBLE PRECISION,           
            name VARCHAR(255)               
        );
        , parameters: None
[2025-02-27T11:13:55.710+0000] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/operators/sql.py", line 274, in execute
    **extra_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 349, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 380, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.

[2025-02-27T11:13:55.720+0000] {taskinstance.py:1373} INFO - Marking task as FAILED. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T111355, end_date=20250227T111355
[2025-02-27T11:13:55.729+0000] {standard_task_runner.py:109} ERROR - Failed to execute job 3 for task create_station_informations_table (duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
; 224)
[2025-02-27T11:13:55.747+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 1
[2025-02-27T11:13:55.776+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T11:39:44.503+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T11:39:44.511+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T11:39:44.512+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T11:39:44.521+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T11:39:44.533+0000] {standard_task_runner.py:57} INFO - Started process 194 to run task
[2025-02-27T11:39:44.543+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp2lr9fbh5']
[2025-02-27T11:39:44.545+0000] {standard_task_runner.py:85} INFO - Job 7: Subtask create_station_informations_table
[2025-02-27T11:39:44.631+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host a00cf8e93560
[2025-02-27T11:39:44.708+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T11:39:44.709+0000] {sql.py:262} INFO - Executing: 
            CREATE TABLE IF NOT EXISTS velib_station_details (
            station_id BIGINT PRIMARY KEY, 
            capacity INT,                   
            lat DOUBLE PRECISION,          
            lon DOUBLE PRECISION,           
            name VARCHAR(255)               
        );
        
[2025-02-27T11:39:44.717+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T11:39:44.802+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T11:39:44.806+0000] {sql.py:375} INFO - Running statement: 
            CREATE TABLE IF NOT EXISTS velib_station_details (
            station_id BIGINT PRIMARY KEY, 
            capacity INT,                   
            lat DOUBLE PRECISION,          
            lon DOUBLE PRECISION,           
            name VARCHAR(255)               
        );
        , parameters: None
[2025-02-27T11:39:44.823+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T113944, end_date=20250227T113944
[2025-02-27T11:39:44.842+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T11:39:44.859+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T11:49:08.296+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T11:49:08.310+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T11:49:08.310+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T11:49:08.339+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T11:49:08.343+0000] {standard_task_runner.py:57} INFO - Started process 187 to run task
[2025-02-27T11:49:08.393+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpffw5xt6p']
[2025-02-27T11:49:08.396+0000] {standard_task_runner.py:85} INFO - Job 6: Subtask create_station_informations_table
[2025-02-27T11:49:08.490+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 08791af1fcb0
[2025-02-27T11:49:08.581+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T11:49:08.581+0000] {sql.py:262} INFO - Executing: 
            DO $$
            BEGIN
                -- Si la table n'existe pas, on s'assure que le type composite n'existe pas non plus
                IF NOT EXISTS (
                    SELECT 1 FROM information_schema.tables 
                    WHERE table_schema = 'public' AND table_name = 'velib_station_details'
                ) THEN
                    IF EXISTS (
                        SELECT 1 FROM pg_type WHERE typname = 'velib_station_details'
                    ) THEN
                        EXECUTE 'DROP TYPE velib_station_details CASCADE';
                    END IF;
                    EXECUTE '
                        CREATE TABLE velib_station_details (
                            station_id BIGINT PRIMARY KEY, 
                            capacity INT,                   
                            lat DOUBLE PRECISION,          
                            lon DOUBLE PRECISION,           
                            name VARCHAR(255)
                        )
                    ';
                END IF;
            END
            $$;
    
[2025-02-27T11:49:08.589+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T11:49:08.711+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T11:49:08.716+0000] {sql.py:375} INFO - Running statement: 
            DO $$
            BEGIN
                -- Si la table n'existe pas, on s'assure que le type composite n'existe pas non plus
                IF NOT EXISTS (
                    SELECT 1 FROM information_schema.tables 
                    WHERE table_schema = 'public' AND table_name = 'velib_station_details'
                ) THEN
                    IF EXISTS (
                        SELECT 1 FROM pg_type WHERE typname = 'velib_station_details'
                    ) THEN
                        EXECUTE 'DROP TYPE velib_station_details CASCADE';
                    END IF;
                    EXECUTE '
                        CREATE TABLE velib_station_details (
                            station_id BIGINT PRIMARY KEY, 
                            capacity INT,                   
                            lat DOUBLE PRECISION,          
                            lon DOUBLE PRECISION,           
                            name VARCHAR(255)
                        )
                    ';
                END IF;
            END
            $$;
    , parameters: None
[2025-02-27T11:49:08.727+0000] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/operators/sql.py", line 274, in execute
    **extra_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 349, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 380, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
CONTEXT:  SQL statement "
                        CREATE TABLE velib_station_details (
                            station_id BIGINT PRIMARY KEY, 
                            capacity INT,                   
                            lat DOUBLE PRECISION,          
                            lon DOUBLE PRECISION,           
                            name VARCHAR(255)
                        )
                    "
PL/pgSQL function inline_code_block line 13 at EXECUTE

[2025-02-27T11:49:08.734+0000] {taskinstance.py:1373} INFO - Marking task as FAILED. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T114908, end_date=20250227T114908
[2025-02-27T11:49:08.742+0000] {standard_task_runner.py:109} ERROR - Failed to execute job 6 for task create_station_informations_table (duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
CONTEXT:  SQL statement "
                        CREATE TABLE velib_station_details (
                            station_id BIGINT PRIMARY KEY, 
                            capacity INT,                   
                            lat DOUBLE PRECISION,          
                            lon DOUBLE PRECISION,           
                            name VARCHAR(255)
                        )
                    "
PL/pgSQL function inline_code_block line 13 at EXECUTE
; 187)
[2025-02-27T11:49:08.775+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 1
[2025-02-27T11:49:08.822+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T11:59:46.342+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T11:59:46.350+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T11:59:46.350+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T11:59:46.358+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T11:59:46.364+0000] {standard_task_runner.py:57} INFO - Started process 210 to run task
[2025-02-27T11:59:46.369+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpwazcr0ex']
[2025-02-27T11:59:46.371+0000] {standard_task_runner.py:85} INFO - Job 2: Subtask create_station_informations_table
[2025-02-27T11:59:46.481+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 8e4c40b4e563
[2025-02-27T11:59:46.696+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T11:59:46.700+0000] {sql.py:262} INFO - Executing: 
            DO $$
            BEGIN
                -- Si la table n'existe pas, on s'assure que le type composite n'existe pas non plus
                IF NOT EXISTS (
                    SELECT 1 FROM information_schema.tables 
                    WHERE table_schema = 'public' AND table_name = 'velib_station_details'
                ) THEN
                    IF EXISTS (
                        SELECT 1 FROM pg_type WHERE typname = 'velib_station_details'
                    ) THEN
                        EXECUTE 'DROP TYPE velib_station_details CASCADE';
                    END IF;
                    EXECUTE '
                        CREATE TABLE velib_station_details (
                            station_id BIGINT PRIMARY KEY, 
                            capacity INT,                   
                            lat DOUBLE PRECISION,          
                            lon DOUBLE PRECISION,           
                            name VARCHAR(255)
                        )
                    ';
                END IF;
            END
            $$;
    
[2025-02-27T11:59:46.716+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T11:59:46.932+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T11:59:46.943+0000] {sql.py:375} INFO - Running statement: 
            DO $$
            BEGIN
                -- Si la table n'existe pas, on s'assure que le type composite n'existe pas non plus
                IF NOT EXISTS (
                    SELECT 1 FROM information_schema.tables 
                    WHERE table_schema = 'public' AND table_name = 'velib_station_details'
                ) THEN
                    IF EXISTS (
                        SELECT 1 FROM pg_type WHERE typname = 'velib_station_details'
                    ) THEN
                        EXECUTE 'DROP TYPE velib_station_details CASCADE';
                    END IF;
                    EXECUTE '
                        CREATE TABLE velib_station_details (
                            station_id BIGINT PRIMARY KEY, 
                            capacity INT,                   
                            lat DOUBLE PRECISION,          
                            lon DOUBLE PRECISION,           
                            name VARCHAR(255)
                        )
                    ';
                END IF;
            END
            $$;
    , parameters: None
[2025-02-27T11:59:46.970+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T115946, end_date=20250227T115946
[2025-02-27T11:59:47.013+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T11:59:47.057+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T12:08:02.858+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T12:08:02.865+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T12:08:02.866+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T12:08:02.874+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T12:08:02.877+0000] {standard_task_runner.py:57} INFO - Started process 179 to run task
[2025-02-27T12:08:02.881+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp1f2nnw15']
[2025-02-27T12:08:02.883+0000] {standard_task_runner.py:85} INFO - Job 2: Subtask create_station_informations_table
[2025-02-27T12:08:02.955+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host d2a66760e739
[2025-02-27T12:08:03.051+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T12:08:03.053+0000] {sql.py:262} INFO - Executing: 
            DO $$
            BEGIN
                IF NOT EXISTS (
                    SELECT 1 FROM information_schema.tables 
                    WHERE table_schema = 'public' AND table_name = 'velib_station_details'
                ) THEN
                    EXECUTE 'DROP TYPE IF EXISTS velib_station_details CASCADE';
                    EXECUTE '
                        CREATE TABLE velib_station_details (
                            station_id BIGINT PRIMARY KEY, 
                            capacity INT,                   
                            lat DOUBLE PRECISION,          
                            lon DOUBLE PRECISION,           
                            name VARCHAR(255)
                        )
                    ';
                END IF;
            END
            $$;
    
    
[2025-02-27T12:08:03.061+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T12:08:03.186+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T12:08:03.190+0000] {sql.py:375} INFO - Running statement: 
            DO $$
            BEGIN
                IF NOT EXISTS (
                    SELECT 1 FROM information_schema.tables 
                    WHERE table_schema = 'public' AND table_name = 'velib_station_details'
                ) THEN
                    EXECUTE 'DROP TYPE IF EXISTS velib_station_details CASCADE';
                    EXECUTE '
                        CREATE TABLE velib_station_details (
                            station_id BIGINT PRIMARY KEY, 
                            capacity INT,                   
                            lat DOUBLE PRECISION,          
                            lon DOUBLE PRECISION,           
                            name VARCHAR(255)
                        )
                    ';
                END IF;
            END
            $$;
    
    , parameters: None
[2025-02-27T12:08:03.210+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T120802, end_date=20250227T120803
[2025-02-27T12:08:03.226+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T12:08:03.259+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T12:23:27.096+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T12:23:27.102+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T12:23:27.103+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T12:23:27.117+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T12:23:27.120+0000] {standard_task_runner.py:57} INFO - Started process 183 to run task
[2025-02-27T12:23:27.123+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpi4v2ec1g']
[2025-02-27T12:23:27.125+0000] {standard_task_runner.py:85} INFO - Job 4: Subtask create_station_informations_table
[2025-02-27T12:23:27.186+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 0972c516a0af
[2025-02-27T12:23:27.243+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T12:23:27.244+0000] {sql.py:262} INFO - Executing: 
            DO $$
            BEGIN
                IF NOT EXISTS (
                    SELECT 1 FROM information_schema.tables 
                    WHERE table_schema = 'public' AND table_name = 'velib_station_details'
                ) THEN
                    EXECUTE 'DROP TYPE IF EXISTS velib_station_details CASCADE';
                    EXECUTE '
                        CREATE TABLE velib_station_details (
                            station_id BIGINT PRIMARY KEY, 
                            capacity INT,                   
                            lat DOUBLE PRECISION,          
                            lon DOUBLE PRECISION,           
                            name VARCHAR(255)
                        )
                    ';
                END IF;
            END
            $$;
    
    
[2025-02-27T12:23:27.253+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T12:23:27.373+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T12:23:27.377+0000] {sql.py:375} INFO - Running statement: 
            DO $$
            BEGIN
                IF NOT EXISTS (
                    SELECT 1 FROM information_schema.tables 
                    WHERE table_schema = 'public' AND table_name = 'velib_station_details'
                ) THEN
                    EXECUTE 'DROP TYPE IF EXISTS velib_station_details CASCADE';
                    EXECUTE '
                        CREATE TABLE velib_station_details (
                            station_id BIGINT PRIMARY KEY, 
                            capacity INT,                   
                            lat DOUBLE PRECISION,          
                            lon DOUBLE PRECISION,           
                            name VARCHAR(255)
                        )
                    ';
                END IF;
            END
            $$;
    
    , parameters: None
[2025-02-27T12:23:27.392+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T122327, end_date=20250227T122327
[2025-02-27T12:23:27.424+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T12:23:27.456+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T12:38:07.501+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T12:38:07.510+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T12:38:07.510+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T12:38:07.520+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T12:38:07.524+0000] {standard_task_runner.py:57} INFO - Started process 178 to run task
[2025-02-27T12:38:07.527+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpj25bzzxa']
[2025-02-27T12:38:07.529+0000] {standard_task_runner.py:85} INFO - Job 2: Subtask create_station_informations_table
[2025-02-27T12:38:07.584+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 493d37524ffa
[2025-02-27T12:38:07.638+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T12:38:07.639+0000] {sql.py:262} INFO - Executing: 
        DO $$
        BEGIN
            IF NOT EXISTS (
                SELECT 1 FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name = 'velib_station_details'
            ) THEN
                CREATE TABLE velib_station_details (
                    station_id BIGINT PRIMARY KEY, 
                    capacity INT,                   
                    lat DOUBLE PRECISION,          
                    lon DOUBLE PRECISION,           
                    name VARCHAR(255)
                );
            END IF;
        END
        $$;
    
[2025-02-27T12:38:07.646+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T12:38:07.750+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T12:38:07.753+0000] {sql.py:375} INFO - Running statement: 
        DO $$
        BEGIN
            IF NOT EXISTS (
                SELECT 1 FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name = 'velib_station_details'
            ) THEN
                CREATE TABLE velib_station_details (
                    station_id BIGINT PRIMARY KEY, 
                    capacity INT,                   
                    lat DOUBLE PRECISION,          
                    lon DOUBLE PRECISION,           
                    name VARCHAR(255)
                );
            END IF;
        END
        $$;
    , parameters: None
[2025-02-27T12:38:07.777+0000] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/operators/sql.py", line 274, in execute
    **extra_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 349, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 380, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
CONTEXT:  SQL statement "CREATE TABLE velib_station_details (
                    station_id BIGINT PRIMARY KEY, 
                    capacity INT,                   
                    lat DOUBLE PRECISION,          
                    lon DOUBLE PRECISION,           
                    name VARCHAR(255)
                )"
PL/pgSQL function inline_code_block line 7 at SQL statement

[2025-02-27T12:38:07.784+0000] {taskinstance.py:1373} INFO - Marking task as FAILED. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T123807, end_date=20250227T123807
[2025-02-27T12:38:07.792+0000] {standard_task_runner.py:109} ERROR - Failed to execute job 2 for task create_station_informations_table (duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
CONTEXT:  SQL statement "CREATE TABLE velib_station_details (
                    station_id BIGINT PRIMARY KEY, 
                    capacity INT,                   
                    lat DOUBLE PRECISION,          
                    lon DOUBLE PRECISION,           
                    name VARCHAR(255)
                )"
PL/pgSQL function inline_code_block line 7 at SQL statement
; 178)
[2025-02-27T12:38:07.829+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 1
[2025-02-27T12:38:07.848+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T12:41:18.848+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T12:41:18.856+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T12:41:18.857+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T12:41:18.869+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T12:41:18.873+0000] {standard_task_runner.py:57} INFO - Started process 180 to run task
[2025-02-27T12:41:18.875+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpv_g7wq1f']
[2025-02-27T12:41:18.878+0000] {standard_task_runner.py:85} INFO - Job 5: Subtask create_station_informations_table
[2025-02-27T12:41:18.931+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 94f4382ac0ba
[2025-02-27T12:41:19.003+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T12:41:19.004+0000] {sql.py:262} INFO - Executing: 
        DO $$
        BEGIN
            IF NOT EXISTS (
                SELECT 1 FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name = 'velib_station_details'
            ) THEN
                CREATE TABLE velib_station_details (
                    station_id BIGINT PRIMARY KEY, 
                    capacity INT,                   
                    lat DOUBLE PRECISION,          
                    lon DOUBLE PRECISION,           
                    name VARCHAR(255)
                );
            END IF;
        END
        $$;
    
[2025-02-27T12:41:19.012+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T12:41:19.121+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T12:41:19.125+0000] {sql.py:375} INFO - Running statement: 
        DO $$
        BEGIN
            IF NOT EXISTS (
                SELECT 1 FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name = 'velib_station_details'
            ) THEN
                CREATE TABLE velib_station_details (
                    station_id BIGINT PRIMARY KEY, 
                    capacity INT,                   
                    lat DOUBLE PRECISION,          
                    lon DOUBLE PRECISION,           
                    name VARCHAR(255)
                );
            END IF;
        END
        $$;
    , parameters: None
[2025-02-27T12:41:19.136+0000] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/operators/sql.py", line 274, in execute
    **extra_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 349, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 380, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
CONTEXT:  SQL statement "CREATE TABLE velib_station_details (
                    station_id BIGINT PRIMARY KEY, 
                    capacity INT,                   
                    lat DOUBLE PRECISION,          
                    lon DOUBLE PRECISION,           
                    name VARCHAR(255)
                )"
PL/pgSQL function inline_code_block line 7 at SQL statement

[2025-02-27T12:41:19.143+0000] {taskinstance.py:1373} INFO - Marking task as FAILED. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T124118, end_date=20250227T124119
[2025-02-27T12:41:19.154+0000] {standard_task_runner.py:109} ERROR - Failed to execute job 5 for task create_station_informations_table (duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
CONTEXT:  SQL statement "CREATE TABLE velib_station_details (
                    station_id BIGINT PRIMARY KEY, 
                    capacity INT,                   
                    lat DOUBLE PRECISION,          
                    lon DOUBLE PRECISION,           
                    name VARCHAR(255)
                )"
PL/pgSQL function inline_code_block line 7 at SQL statement
; 180)
[2025-02-27T12:41:19.180+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 1
[2025-02-27T12:41:19.207+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T13:16:20.220+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T13:16:20.231+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T13:16:20.232+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T13:16:20.243+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T13:16:20.249+0000] {standard_task_runner.py:57} INFO - Started process 209 to run task
[2025-02-27T13:16:20.252+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp_hc0sas5']
[2025-02-27T13:16:20.254+0000] {standard_task_runner.py:85} INFO - Job 4: Subtask create_station_informations_table
[2025-02-27T13:16:20.297+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 3f89a3e69849
[2025-02-27T13:16:20.391+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T13:16:20.391+0000] {sql.py:262} INFO - Executing: 
        DO $$
        BEGIN
            IF NOT EXISTS (
                SELECT 1 FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name = 'velib_station_details'
            ) THEN
                CREATE TABLE velib_station_details (
                    station_id BIGINT PRIMARY KEY, 
                    capacity INT,                   
                    lat DOUBLE PRECISION,          
                    lon DOUBLE PRECISION,           
                    name VARCHAR(255)
                );
            END IF;
        END
        $$;
    
[2025-02-27T13:16:20.398+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T13:16:20.521+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T13:16:20.525+0000] {sql.py:375} INFO - Running statement: 
        DO $$
        BEGIN
            IF NOT EXISTS (
                SELECT 1 FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name = 'velib_station_details'
            ) THEN
                CREATE TABLE velib_station_details (
                    station_id BIGINT PRIMARY KEY, 
                    capacity INT,                   
                    lat DOUBLE PRECISION,          
                    lon DOUBLE PRECISION,           
                    name VARCHAR(255)
                );
            END IF;
        END
        $$;
    , parameters: None
[2025-02-27T13:16:20.543+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T131620, end_date=20250227T131620
[2025-02-27T13:16:20.559+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T13:16:20.579+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T13:19:50.679+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T13:19:50.684+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T13:19:50.686+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T13:19:50.696+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T13:19:50.699+0000] {standard_task_runner.py:57} INFO - Started process 179 to run task
[2025-02-27T13:19:50.705+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpsfl8pgdf']
[2025-02-27T13:19:50.714+0000] {standard_task_runner.py:85} INFO - Job 4: Subtask create_station_informations_table
[2025-02-27T13:19:50.791+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 1769bb992e56
[2025-02-27T13:19:50.878+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T13:19:50.879+0000] {sql.py:262} INFO - Executing: 
        DO $$
        BEGIN
            -- Check first if a type with the same name exists and drop it if it does
            IF EXISTS (SELECT 1 FROM pg_type WHERE typname = 'velib_station_details') THEN
                EXECUTE 'DROP TYPE IF EXISTS velib_station_details CASCADE';
            END IF;
            -- Then, create the table if it does not exist
            IF NOT EXISTS (
                SELECT 1 FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name = 'velib_station_details'
            ) THEN
                EXECUTE '
                    CREATE TABLE velib_station_details (
                        station_id BIGINT PRIMARY KEY, 
                        capacity INT,                   
                        lat DOUBLE PRECISION,          
                        lon DOUBLE PRECISION,           
                        name VARCHAR(255)
                    );
                ';
            END IF;
        END
        $$;
    
[2025-02-27T13:19:50.885+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T13:19:51.009+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T13:19:51.014+0000] {sql.py:375} INFO - Running statement: 
        DO $$
        BEGIN
            -- Check first if a type with the same name exists and drop it if it does
            IF EXISTS (SELECT 1 FROM pg_type WHERE typname = 'velib_station_details') THEN
                EXECUTE 'DROP TYPE IF EXISTS velib_station_details CASCADE';
            END IF;
            -- Then, create the table if it does not exist
            IF NOT EXISTS (
                SELECT 1 FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name = 'velib_station_details'
            ) THEN
                EXECUTE '
                    CREATE TABLE velib_station_details (
                        station_id BIGINT PRIMARY KEY, 
                        capacity INT,                   
                        lat DOUBLE PRECISION,          
                        lon DOUBLE PRECISION,           
                        name VARCHAR(255)
                    );
                ';
            END IF;
        END
        $$;
    , parameters: None
[2025-02-27T13:19:51.028+0000] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/operators/sql.py", line 274, in execute
    **extra_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 349, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 380, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
CONTEXT:  SQL statement "
                    CREATE TABLE velib_station_details (
                        station_id BIGINT PRIMARY KEY, 
                        capacity INT,                   
                        lat DOUBLE PRECISION,          
                        lon DOUBLE PRECISION,           
                        name VARCHAR(255)
                    );
                "
PL/pgSQL function inline_code_block line 12 at EXECUTE

[2025-02-27T13:19:51.037+0000] {taskinstance.py:1373} INFO - Marking task as FAILED. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T131950, end_date=20250227T131951
[2025-02-27T13:19:51.050+0000] {standard_task_runner.py:109} ERROR - Failed to execute job 4 for task create_station_informations_table (duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
CONTEXT:  SQL statement "
                    CREATE TABLE velib_station_details (
                        station_id BIGINT PRIMARY KEY, 
                        capacity INT,                   
                        lat DOUBLE PRECISION,          
                        lon DOUBLE PRECISION,           
                        name VARCHAR(255)
                    );
                "
PL/pgSQL function inline_code_block line 12 at EXECUTE
; 179)
[2025-02-27T13:19:51.056+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 1
[2025-02-27T13:19:51.085+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T13:22:33.797+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T13:22:33.807+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T13:22:33.808+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T13:22:33.818+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T13:22:33.822+0000] {standard_task_runner.py:57} INFO - Started process 177 to run task
[2025-02-27T13:22:33.825+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmplq4gznwn']
[2025-02-27T13:22:33.829+0000] {standard_task_runner.py:85} INFO - Job 2: Subtask create_station_informations_table
[2025-02-27T13:22:33.874+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host f51c37a32fa6
[2025-02-27T13:22:33.931+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T13:22:33.931+0000] {sql.py:262} INFO - Executing: 
        DO $$
        BEGIN
            -- Check first if a type with the same name exists and drop it if it does
            IF EXISTS (SELECT 1 FROM pg_type WHERE typname = 'velib_station_details') THEN
                EXECUTE 'DROP TYPE IF EXISTS velib_station_details CASCADE';
            END IF;
            -- Then, create the table if it does not exist
            IF NOT EXISTS (
                SELECT 1 FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name = 'velib_station_details'
            ) THEN
                EXECUTE '
                    CREATE TABLE velib_station_details (
                        station_id BIGINT PRIMARY KEY, 
                        capacity INT,                   
                        lat DOUBLE PRECISION,          
                        lon DOUBLE PRECISION,           
                        name VARCHAR(255)
                    );
                ';
            END IF;
        END
        $$;
    
[2025-02-27T13:22:33.939+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T13:22:34.072+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T13:22:34.075+0000] {sql.py:375} INFO - Running statement: 
        DO $$
        BEGIN
            -- Check first if a type with the same name exists and drop it if it does
            IF EXISTS (SELECT 1 FROM pg_type WHERE typname = 'velib_station_details') THEN
                EXECUTE 'DROP TYPE IF EXISTS velib_station_details CASCADE';
            END IF;
            -- Then, create the table if it does not exist
            IF NOT EXISTS (
                SELECT 1 FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name = 'velib_station_details'
            ) THEN
                EXECUTE '
                    CREATE TABLE velib_station_details (
                        station_id BIGINT PRIMARY KEY, 
                        capacity INT,                   
                        lat DOUBLE PRECISION,          
                        lon DOUBLE PRECISION,           
                        name VARCHAR(255)
                    );
                ';
            END IF;
        END
        $$;
    , parameters: None
[2025-02-27T13:22:34.093+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T132233, end_date=20250227T132234
[2025-02-27T13:22:34.127+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T13:22:34.161+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T13:33:11.892+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T13:33:11.898+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T13:33:11.898+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T13:33:11.908+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T13:33:11.913+0000] {standard_task_runner.py:57} INFO - Started process 183 to run task
[2025-02-27T13:33:11.915+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpcw8s_kxp']
[2025-02-27T13:33:11.917+0000] {standard_task_runner.py:85} INFO - Job 4: Subtask create_station_informations_table
[2025-02-27T13:33:11.987+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 302ea8356a15
[2025-02-27T13:33:12.046+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T13:33:12.046+0000] {sql.py:262} INFO - Executing: 
        DO $$
        BEGIN
            -- Check first if a type with the same name exists and drop it if it does
            IF EXISTS (SELECT 1 FROM pg_type WHERE typname = 'velib_station_details') THEN
                EXECUTE 'DROP TYPE IF EXISTS velib_station_details CASCADE';
            END IF;
            -- Then, create the table if it does not exist
            IF NOT EXISTS (
                SELECT 1 FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name = 'velib_station_details'
            ) THEN
                EXECUTE '
                    CREATE TABLE velib_station_details (
                        station_id BIGINT PRIMARY KEY, 
                        capacity INT,                   
                        lat DOUBLE PRECISION,          
                        lon DOUBLE PRECISION,           
                        name VARCHAR(255)
                    );
                ';
            END IF;
        END
        $$;
    
[2025-02-27T13:33:12.054+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T13:33:12.173+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T13:33:12.175+0000] {sql.py:375} INFO - Running statement: 
        DO $$
        BEGIN
            -- Check first if a type with the same name exists and drop it if it does
            IF EXISTS (SELECT 1 FROM pg_type WHERE typname = 'velib_station_details') THEN
                EXECUTE 'DROP TYPE IF EXISTS velib_station_details CASCADE';
            END IF;
            -- Then, create the table if it does not exist
            IF NOT EXISTS (
                SELECT 1 FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name = 'velib_station_details'
            ) THEN
                EXECUTE '
                    CREATE TABLE velib_station_details (
                        station_id BIGINT PRIMARY KEY, 
                        capacity INT,                   
                        lat DOUBLE PRECISION,          
                        lon DOUBLE PRECISION,           
                        name VARCHAR(255)
                    );
                ';
            END IF;
        END
        $$;
    , parameters: None
[2025-02-27T13:33:12.184+0000] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/operators/sql.py", line 274, in execute
    **extra_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 349, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 380, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
CONTEXT:  SQL statement "
                    CREATE TABLE velib_station_details (
                        station_id BIGINT PRIMARY KEY, 
                        capacity INT,                   
                        lat DOUBLE PRECISION,          
                        lon DOUBLE PRECISION,           
                        name VARCHAR(255)
                    );
                "
PL/pgSQL function inline_code_block line 12 at EXECUTE

[2025-02-27T13:33:12.189+0000] {taskinstance.py:1373} INFO - Marking task as FAILED. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T133311, end_date=20250227T133312
[2025-02-27T13:33:12.196+0000] {standard_task_runner.py:109} ERROR - Failed to execute job 4 for task create_station_informations_table (duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
CONTEXT:  SQL statement "
                    CREATE TABLE velib_station_details (
                        station_id BIGINT PRIMARY KEY, 
                        capacity INT,                   
                        lat DOUBLE PRECISION,          
                        lon DOUBLE PRECISION,           
                        name VARCHAR(255)
                    );
                "
PL/pgSQL function inline_code_block line 12 at EXECUTE
; 183)
[2025-02-27T13:33:12.222+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 1
[2025-02-27T13:33:12.238+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T13:50:51.469+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T13:50:51.477+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T13:50:51.479+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T13:50:51.489+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T13:50:51.493+0000] {standard_task_runner.py:57} INFO - Started process 184 to run task
[2025-02-27T13:50:51.495+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp_c6124m6']
[2025-02-27T13:50:51.497+0000] {standard_task_runner.py:85} INFO - Job 3: Subtask create_station_informations_table
[2025-02-27T13:50:51.541+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 0dc2b4101260
[2025-02-27T13:50:51.611+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T13:50:51.612+0000] {sql.py:262} INFO - Executing: 
        DO $$
        BEGIN
            -- Check first if a type with the same name exists and drop it if it does
            IF EXISTS (SELECT 1 FROM pg_type WHERE typname = 'velib_station_details') THEN
                EXECUTE 'DROP TYPE IF EXISTS velib_station_details CASCADE';
            END IF;
            -- Then, create the table if it does not exist
            IF NOT EXISTS (
                SELECT 1 FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name = 'velib_station_details'
            ) THEN
                EXECUTE '
                    CREATE TABLE velib_station_details (
                        station_id BIGINT PRIMARY KEY, 
                        capacity INT,                   
                        lat DOUBLE PRECISION,          
                        lon DOUBLE PRECISION,           
                        name VARCHAR(255)
                    );
                ';
            END IF;
        END
        $$;
    
[2025-02-27T13:50:51.621+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T13:50:51.728+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T13:50:51.731+0000] {sql.py:375} INFO - Running statement: 
        DO $$
        BEGIN
            -- Check first if a type with the same name exists and drop it if it does
            IF EXISTS (SELECT 1 FROM pg_type WHERE typname = 'velib_station_details') THEN
                EXECUTE 'DROP TYPE IF EXISTS velib_station_details CASCADE';
            END IF;
            -- Then, create the table if it does not exist
            IF NOT EXISTS (
                SELECT 1 FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name = 'velib_station_details'
            ) THEN
                EXECUTE '
                    CREATE TABLE velib_station_details (
                        station_id BIGINT PRIMARY KEY, 
                        capacity INT,                   
                        lat DOUBLE PRECISION,          
                        lon DOUBLE PRECISION,           
                        name VARCHAR(255)
                    );
                ';
            END IF;
        END
        $$;
    , parameters: None
[2025-02-27T13:50:51.751+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T135051, end_date=20250227T135051
[2025-02-27T13:50:51.800+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T13:50:51.835+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T13:58:12.719+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T13:58:12.728+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T13:58:12.728+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T13:58:12.736+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T13:58:12.740+0000] {standard_task_runner.py:57} INFO - Started process 186 to run task
[2025-02-27T13:58:12.742+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpdf6ixk_q']
[2025-02-27T13:58:12.750+0000] {standard_task_runner.py:85} INFO - Job 3: Subtask create_station_informations_table
[2025-02-27T13:58:12.830+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 90fb001151ab
[2025-02-27T13:58:12.904+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T13:58:12.905+0000] {sql.py:262} INFO - Executing: 
        BEGIN;
            DROP TABLE IF EXISTS velib_station_details CASCADE;
            CREATE TABLE velib_station_details (
                station_id BIGINT PRIMARY KEY, 
                capacity INT,                   
                lat DOUBLE PRECISION,          
                lon DOUBLE PRECISION,           
                name VARCHAR(255)
            );
        COMMIT;
    
[2025-02-27T13:58:12.912+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T13:58:13.032+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T13:58:13.037+0000] {sql.py:375} INFO - Running statement: 
        BEGIN;
            DROP TABLE IF EXISTS velib_station_details CASCADE;
            CREATE TABLE velib_station_details (
                station_id BIGINT PRIMARY KEY, 
                capacity INT,                   
                lat DOUBLE PRECISION,          
                lon DOUBLE PRECISION,           
                name VARCHAR(255)
            );
        COMMIT;
    , parameters: None
[2025-02-27T13:58:13.054+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T135812, end_date=20250227T135813
[2025-02-27T13:58:13.087+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T13:58:13.106+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T14:03:45.446+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T14:03:45.454+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T14:03:45.454+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T14:03:45.469+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T14:03:45.473+0000] {standard_task_runner.py:57} INFO - Started process 184 to run task
[2025-02-27T14:03:45.478+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmplosldpx6']
[2025-02-27T14:03:45.480+0000] {standard_task_runner.py:85} INFO - Job 2: Subtask create_station_informations_table
[2025-02-27T14:03:45.550+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 5b8533a39e96
[2025-02-27T14:03:45.626+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T14:03:45.627+0000] {sql.py:262} INFO - Executing: 
        BEGIN;
            DROP TABLE IF EXISTS velib_station_details CASCADE;
            CREATE TABLE velib_station_details (
                station_id BIGINT PRIMARY KEY, 
                capacity INT,                   
                lat DOUBLE PRECISION,          
                lon DOUBLE PRECISION,           
                name VARCHAR(255)
            );
        COMMIT;
    
[2025-02-27T14:03:45.636+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T14:03:45.797+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T14:03:45.801+0000] {sql.py:375} INFO - Running statement: 
        BEGIN;
            DROP TABLE IF EXISTS velib_station_details CASCADE;
            CREATE TABLE velib_station_details (
                station_id BIGINT PRIMARY KEY, 
                capacity INT,                   
                lat DOUBLE PRECISION,          
                lon DOUBLE PRECISION,           
                name VARCHAR(255)
            );
        COMMIT;
    , parameters: None
[2025-02-27T14:03:45.818+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T140345, end_date=20250227T140345
[2025-02-27T14:03:45.864+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T14:03:45.903+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T14:17:26.688+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T14:17:26.693+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T14:17:26.693+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T14:17:26.702+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T14:17:26.707+0000] {standard_task_runner.py:57} INFO - Started process 193 to run task
[2025-02-27T14:17:26.713+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp3rhg5oz2']
[2025-02-27T14:17:26.716+0000] {standard_task_runner.py:85} INFO - Job 3: Subtask create_station_informations_table
[2025-02-27T14:17:26.784+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host c6d37e3f50d8
[2025-02-27T14:17:26.885+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T14:17:26.888+0000] {sql.py:262} INFO - Executing: 
        BEGIN;
            DROP TABLE IF EXISTS velib_station_details CASCADE;
            CREATE TABLE velib_station_details (
                station_id BIGINT PRIMARY KEY, 
                capacity INT,                   
                lat DOUBLE PRECISION,          
                lon DOUBLE PRECISION,           
                name VARCHAR(255)
            );
        COMMIT;
    
[2025-02-27T14:17:26.920+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T14:17:27.047+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T14:17:27.050+0000] {sql.py:375} INFO - Running statement: 
        BEGIN;
            DROP TABLE IF EXISTS velib_station_details CASCADE;
            CREATE TABLE velib_station_details (
                station_id BIGINT PRIMARY KEY, 
                capacity INT,                   
                lat DOUBLE PRECISION,          
                lon DOUBLE PRECISION,           
                name VARCHAR(255)
            );
        COMMIT;
    , parameters: None
[2025-02-27T14:17:27.057+0000] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/operators/sql.py", line 274, in execute
    **extra_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 349, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 380, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.

[2025-02-27T14:17:27.080+0000] {taskinstance.py:1373} INFO - Marking task as FAILED. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T141726, end_date=20250227T141727
[2025-02-27T14:17:27.088+0000] {standard_task_runner.py:109} ERROR - Failed to execute job 3 for task create_station_informations_table (duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
; 193)
[2025-02-27T14:17:27.096+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 1
[2025-02-27T14:17:27.113+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T14:24:45.216+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T14:24:45.222+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T14:24:45.222+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T14:24:45.231+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T14:24:45.235+0000] {standard_task_runner.py:57} INFO - Started process 186 to run task
[2025-02-27T14:24:45.238+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpt8e180o1']
[2025-02-27T14:24:45.242+0000] {standard_task_runner.py:85} INFO - Job 2: Subtask create_station_informations_table
[2025-02-27T14:24:45.306+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host dc3a30e27f13
[2025-02-27T14:24:45.365+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T14:24:45.367+0000] {sql.py:262} INFO - Executing: 
        BEGIN;
            DROP TABLE IF EXISTS velib_station_details CASCADE;
            CREATE TABLE velib_station_details (
                station_id BIGINT PRIMARY KEY, 
                capacity INT,                   
                lat DOUBLE PRECISION,          
                lon DOUBLE PRECISION,           
                name VARCHAR(255)
            );
        COMMIT;
    
[2025-02-27T14:24:45.372+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T14:24:45.487+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T14:24:45.490+0000] {sql.py:375} INFO - Running statement: 
        BEGIN;
            DROP TABLE IF EXISTS velib_station_details CASCADE;
            CREATE TABLE velib_station_details (
                station_id BIGINT PRIMARY KEY, 
                capacity INT,                   
                lat DOUBLE PRECISION,          
                lon DOUBLE PRECISION,           
                name VARCHAR(255)
            );
        COMMIT;
    , parameters: None
[2025-02-27T14:24:45.502+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T142445, end_date=20250227T142445
[2025-02-27T14:24:45.544+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T14:24:45.569+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T14:30:56.367+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T14:30:56.373+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T14:30:56.373+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T14:30:56.382+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T14:30:56.386+0000] {standard_task_runner.py:57} INFO - Started process 183 to run task
[2025-02-27T14:30:56.389+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpzhfvw8sc']
[2025-02-27T14:30:56.391+0000] {standard_task_runner.py:85} INFO - Job 2: Subtask create_station_informations_table
[2025-02-27T14:30:56.449+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host a552db7362e5
[2025-02-27T14:30:56.509+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T14:30:56.509+0000] {sql.py:262} INFO - Executing: 
        BEGIN;
            -- Vrifiez d'abord si la table n'existe pas avant de la crer
            DO $$
            BEGIN
                IF NOT EXISTS (SELECT FROM pg_tables WHERE schemaname = 'public' AND tablename = 'velib_station_details') THEN
                    CREATE TABLE public.velib_station_details (
                        station_id BIGINT PRIMARY KEY,
                        capacity INT,
                        lat DOUBLE PRECISION,
                        lon DOUBLE PRECISION,
                        name VARCHAR(255)
                    );
                END IF;
            END
            $$;
        COMMIT;
        
[2025-02-27T14:30:56.516+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T14:30:56.643+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T14:30:56.646+0000] {sql.py:375} INFO - Running statement: 
        BEGIN;
            -- Vrifiez d'abord si la table n'existe pas avant de la crer
            DO $$
            BEGIN
                IF NOT EXISTS (SELECT FROM pg_tables WHERE schemaname = 'public' AND tablename = 'velib_station_details') THEN
                    CREATE TABLE public.velib_station_details (
                        station_id BIGINT PRIMARY KEY,
                        capacity INT,
                        lat DOUBLE PRECISION,
                        lon DOUBLE PRECISION,
                        name VARCHAR(255)
                    );
                END IF;
            END
            $$;
        COMMIT;
        , parameters: None
[2025-02-27T14:30:56.657+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T143056, end_date=20250227T143056
[2025-02-27T14:30:56.694+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T14:30:56.714+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T14:51:50.373+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T14:51:50.379+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T14:51:50.379+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T14:51:50.388+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T14:51:50.393+0000] {standard_task_runner.py:57} INFO - Started process 274 to run task
[2025-02-27T14:51:50.396+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpc3hzkjnf']
[2025-02-27T14:51:50.400+0000] {standard_task_runner.py:85} INFO - Job 4: Subtask create_station_informations_table
[2025-02-27T14:51:50.541+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host b6fe49d0fb59
[2025-02-27T14:51:50.658+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T14:51:50.659+0000] {sql.py:262} INFO - Executing: 
        BEGIN;
            -- Vrifiez d'abord si la table n'existe pas avant de la crer
            DO $$
            BEGIN
                IF NOT EXISTS (SELECT FROM pg_tables WHERE schemaname = 'public' AND tablename = 'velib_station_details') THEN
                    CREATE TABLE public.velib_station_details (
                        station_id BIGINT PRIMARY KEY,
                        capacity INT,
                        lat DOUBLE PRECISION,
                        lon DOUBLE PRECISION,
                        name VARCHAR(255)
                    );
                END IF;
            END
            $$;
        COMMIT;
        
[2025-02-27T14:51:50.670+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T14:51:50.786+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T14:51:50.795+0000] {sql.py:375} INFO - Running statement: 
        BEGIN;
            -- Vrifiez d'abord si la table n'existe pas avant de la crer
            DO $$
            BEGIN
                IF NOT EXISTS (SELECT FROM pg_tables WHERE schemaname = 'public' AND tablename = 'velib_station_details') THEN
                    CREATE TABLE public.velib_station_details (
                        station_id BIGINT PRIMARY KEY,
                        capacity INT,
                        lat DOUBLE PRECISION,
                        lon DOUBLE PRECISION,
                        name VARCHAR(255)
                    );
                END IF;
            END
            $$;
        COMMIT;
        , parameters: None
[2025-02-27T14:51:50.815+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T145150, end_date=20250227T145150
[2025-02-27T14:51:50.865+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T14:51:50.903+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T15:08:23.513+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T15:08:23.517+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T15:08:23.518+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T15:08:23.531+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T15:08:23.534+0000] {standard_task_runner.py:57} INFO - Started process 179 to run task
[2025-02-27T15:08:23.537+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpfm1ks3go']
[2025-02-27T15:08:23.540+0000] {standard_task_runner.py:85} INFO - Job 2: Subtask create_station_informations_table
[2025-02-27T15:08:23.607+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 0177d843a7c4
[2025-02-27T15:08:23.680+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T15:08:23.681+0000] {sql.py:262} INFO - Executing: 
        BEGIN;
            -- Vrifiez d'abord si la table n'existe pas avant de la crer
            DO $$
            BEGIN
                IF NOT EXISTS (SELECT FROM pg_tables WHERE schemaname = 'public' AND tablename = 'velib_station_details') THEN
                    CREATE TABLE public.velib_station_details (
                        station_id BIGINT PRIMARY KEY,
                        capacity INT,
                        lat DOUBLE PRECISION,
                        lon DOUBLE PRECISION,
                        name VARCHAR(255)
                    );
                END IF;
            END
            $$;
        COMMIT;
        
[2025-02-27T15:08:23.689+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T15:08:23.799+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T15:08:23.803+0000] {sql.py:375} INFO - Running statement: 
        BEGIN;
            -- Vrifiez d'abord si la table n'existe pas avant de la crer
            DO $$
            BEGIN
                IF NOT EXISTS (SELECT FROM pg_tables WHERE schemaname = 'public' AND tablename = 'velib_station_details') THEN
                    CREATE TABLE public.velib_station_details (
                        station_id BIGINT PRIMARY KEY,
                        capacity INT,
                        lat DOUBLE PRECISION,
                        lon DOUBLE PRECISION,
                        name VARCHAR(255)
                    );
                END IF;
            END
            $$;
        COMMIT;
        , parameters: None
[2025-02-27T15:08:23.814+0000] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/operators/sql.py", line 274, in execute
    **extra_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 349, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 380, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
CONTEXT:  SQL statement "CREATE TABLE public.velib_station_details (
                        station_id BIGINT PRIMARY KEY,
                        capacity INT,
                        lat DOUBLE PRECISION,
                        lon DOUBLE PRECISION,
                        name VARCHAR(255)
                    )"
PL/pgSQL function inline_code_block line 4 at SQL statement

[2025-02-27T15:08:23.820+0000] {taskinstance.py:1373} INFO - Marking task as FAILED. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T150823, end_date=20250227T150823
[2025-02-27T15:08:23.829+0000] {standard_task_runner.py:109} ERROR - Failed to execute job 2 for task create_station_informations_table (duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
CONTEXT:  SQL statement "CREATE TABLE public.velib_station_details (
                        station_id BIGINT PRIMARY KEY,
                        capacity INT,
                        lat DOUBLE PRECISION,
                        lon DOUBLE PRECISION,
                        name VARCHAR(255)
                    )"
PL/pgSQL function inline_code_block line 4 at SQL statement
; 179)
[2025-02-27T15:08:23.841+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 1
[2025-02-27T15:08:23.866+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T15:11:26.045+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T15:11:26.051+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T15:11:26.051+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T15:11:26.062+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T15:11:26.066+0000] {standard_task_runner.py:57} INFO - Started process 178 to run task
[2025-02-27T15:11:26.069+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpggu0fcrb']
[2025-02-27T15:11:26.071+0000] {standard_task_runner.py:85} INFO - Job 5: Subtask create_station_informations_table
[2025-02-27T15:11:26.118+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 8d4390e24c8f
[2025-02-27T15:11:26.184+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T15:11:26.185+0000] {sql.py:262} INFO - Executing: 
        BEGIN;
            -- Vrifiez d'abord si la table n'existe pas avant de la crer
            DO $$
            BEGIN
                IF NOT EXISTS (SELECT FROM pg_tables WHERE schemaname = 'public' AND tablename = 'velib_station_details') THEN
                    CREATE TABLE public.velib_station_details (
                        station_id BIGINT PRIMARY KEY,
                        capacity INT,
                        lat DOUBLE PRECISION,
                        lon DOUBLE PRECISION,
                        name VARCHAR(255)
                    );
                END IF;
            END
            $$;
        COMMIT;
        
[2025-02-27T15:11:26.191+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T15:11:26.305+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T15:11:26.310+0000] {sql.py:375} INFO - Running statement: 
        BEGIN;
            -- Vrifiez d'abord si la table n'existe pas avant de la crer
            DO $$
            BEGIN
                IF NOT EXISTS (SELECT FROM pg_tables WHERE schemaname = 'public' AND tablename = 'velib_station_details') THEN
                    CREATE TABLE public.velib_station_details (
                        station_id BIGINT PRIMARY KEY,
                        capacity INT,
                        lat DOUBLE PRECISION,
                        lon DOUBLE PRECISION,
                        name VARCHAR(255)
                    );
                END IF;
            END
            $$;
        COMMIT;
        , parameters: None
[2025-02-27T15:11:26.320+0000] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/operators/sql.py", line 274, in execute
    **extra_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 349, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 380, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
CONTEXT:  SQL statement "CREATE TABLE public.velib_station_details (
                        station_id BIGINT PRIMARY KEY,
                        capacity INT,
                        lat DOUBLE PRECISION,
                        lon DOUBLE PRECISION,
                        name VARCHAR(255)
                    )"
PL/pgSQL function inline_code_block line 4 at SQL statement

[2025-02-27T15:11:26.325+0000] {taskinstance.py:1373} INFO - Marking task as FAILED. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T151126, end_date=20250227T151126
[2025-02-27T15:11:26.332+0000] {standard_task_runner.py:109} ERROR - Failed to execute job 5 for task create_station_informations_table (duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
CONTEXT:  SQL statement "CREATE TABLE public.velib_station_details (
                        station_id BIGINT PRIMARY KEY,
                        capacity INT,
                        lat DOUBLE PRECISION,
                        lon DOUBLE PRECISION,
                        name VARCHAR(255)
                    )"
PL/pgSQL function inline_code_block line 4 at SQL statement
; 178)
[2025-02-27T15:11:26.372+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 1
[2025-02-27T15:11:26.389+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T15:42:20.972+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T15:42:20.978+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T15:42:20.978+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T15:42:20.987+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T15:42:20.992+0000] {standard_task_runner.py:57} INFO - Started process 178 to run task
[2025-02-27T15:42:20.996+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpjixhj6c3']
[2025-02-27T15:42:20.999+0000] {standard_task_runner.py:85} INFO - Job 3: Subtask create_station_informations_table
[2025-02-27T15:42:21.059+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 0d5c9f65f64a
[2025-02-27T15:42:21.116+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T15:42:21.118+0000] {sql.py:262} INFO - Executing: 
        BEGIN;
            -- Vrifiez d'abord si la table n'existe pas avant de la crer
            DO $$
            BEGIN
                IF NOT EXISTS (SELECT FROM pg_tables WHERE schemaname = 'public' AND tablename = 'velib_station_details') THEN
                    CREATE TABLE public.velib_station_details (
                        station_id BIGINT PRIMARY KEY,
                        capacity INT,
                        lat DOUBLE PRECISION,
                        lon DOUBLE PRECISION,
                        name VARCHAR(255)
                    );
                END IF;
            END
            $$;
        COMMIT;
        
[2025-02-27T15:42:21.125+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T15:42:21.237+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T15:42:21.241+0000] {sql.py:375} INFO - Running statement: 
        BEGIN;
            -- Vrifiez d'abord si la table n'existe pas avant de la crer
            DO $$
            BEGIN
                IF NOT EXISTS (SELECT FROM pg_tables WHERE schemaname = 'public' AND tablename = 'velib_station_details') THEN
                    CREATE TABLE public.velib_station_details (
                        station_id BIGINT PRIMARY KEY,
                        capacity INT,
                        lat DOUBLE PRECISION,
                        lon DOUBLE PRECISION,
                        name VARCHAR(255)
                    );
                END IF;
            END
            $$;
        COMMIT;
        , parameters: None
[2025-02-27T15:42:21.251+0000] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/operators/sql.py", line 274, in execute
    **extra_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 349, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 380, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
CONTEXT:  SQL statement "CREATE TABLE public.velib_station_details (
                        station_id BIGINT PRIMARY KEY,
                        capacity INT,
                        lat DOUBLE PRECISION,
                        lon DOUBLE PRECISION,
                        name VARCHAR(255)
                    )"
PL/pgSQL function inline_code_block line 4 at SQL statement

[2025-02-27T15:42:21.258+0000] {taskinstance.py:1373} INFO - Marking task as FAILED. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T154220, end_date=20250227T154221
[2025-02-27T15:42:21.267+0000] {standard_task_runner.py:109} ERROR - Failed to execute job 3 for task create_station_informations_table (duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
CONTEXT:  SQL statement "CREATE TABLE public.velib_station_details (
                        station_id BIGINT PRIMARY KEY,
                        capacity INT,
                        lat DOUBLE PRECISION,
                        lon DOUBLE PRECISION,
                        name VARCHAR(255)
                    )"
PL/pgSQL function inline_code_block line 4 at SQL statement
; 178)
[2025-02-27T15:42:21.298+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 1
[2025-02-27T15:42:21.316+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T15:50:24.370+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T15:50:24.375+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T15:50:24.376+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T15:50:24.384+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T15:50:24.389+0000] {standard_task_runner.py:57} INFO - Started process 182 to run task
[2025-02-27T15:50:24.392+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpb39r9_y7']
[2025-02-27T15:50:24.396+0000] {standard_task_runner.py:85} INFO - Job 2: Subtask create_station_informations_table
[2025-02-27T15:50:24.446+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host b95c8530fb6c
[2025-02-27T15:50:24.506+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T15:50:24.507+0000] {sql.py:262} INFO - Executing: 
        
        CREATE TABLE IF NOT EXISTS velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        
[2025-02-27T15:50:24.513+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T15:50:24.622+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T15:50:24.626+0000] {sql.py:375} INFO - Running statement: 
        
        CREATE TABLE IF NOT EXISTS velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        , parameters: None
[2025-02-27T15:50:24.640+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T155024, end_date=20250227T155024
[2025-02-27T15:50:24.695+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T15:50:24.729+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T15:53:07.783+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T15:53:07.789+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T15:53:07.789+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T15:53:07.798+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T15:53:07.802+0000] {standard_task_runner.py:57} INFO - Started process 177 to run task
[2025-02-27T15:53:07.804+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpc1c3b8_a']
[2025-02-27T15:53:07.811+0000] {standard_task_runner.py:85} INFO - Job 2: Subtask create_station_informations_table
[2025-02-27T15:53:07.863+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host f5aed095ee09
[2025-02-27T15:53:07.923+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T15:53:07.924+0000] {sql.py:262} INFO - Executing: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        
[2025-02-27T15:53:07.929+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T15:53:08.054+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T15:53:08.059+0000] {sql.py:375} INFO - Running statement: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        , parameters: None
[2025-02-27T15:53:08.073+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T155307, end_date=20250227T155308
[2025-02-27T15:53:08.108+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T15:53:08.127+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T16:06:30.075+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:06:30.082+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:06:30.082+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T16:06:30.094+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T16:06:30.100+0000] {standard_task_runner.py:57} INFO - Started process 177 to run task
[2025-02-27T16:06:30.103+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpu58tjlxe']
[2025-02-27T16:06:30.107+0000] {standard_task_runner.py:85} INFO - Job 4: Subtask create_station_informations_table
[2025-02-27T16:06:30.171+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 70227d8e9381
[2025-02-27T16:06:30.289+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T16:06:30.290+0000] {sql.py:262} INFO - Executing: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        
[2025-02-27T16:06:30.305+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T16:06:30.442+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T16:06:30.446+0000] {sql.py:375} INFO - Running statement: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        , parameters: None
[2025-02-27T16:06:30.464+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T160630, end_date=20250227T160630
[2025-02-27T16:06:30.489+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T16:06:30.507+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T16:20:02.581+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:20:02.586+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:20:02.587+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T16:20:02.595+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T16:20:02.600+0000] {standard_task_runner.py:57} INFO - Started process 180 to run task
[2025-02-27T16:20:02.604+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp7x8zkopc']
[2025-02-27T16:20:02.608+0000] {standard_task_runner.py:85} INFO - Job 2: Subtask create_station_informations_table
[2025-02-27T16:20:02.675+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host e84fbebffd18
[2025-02-27T16:20:02.730+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T16:20:02.730+0000] {sql.py:262} INFO - Executing: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        
[2025-02-27T16:20:02.735+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T16:20:02.868+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T16:20:02.872+0000] {sql.py:375} INFO - Running statement: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        , parameters: None
[2025-02-27T16:20:02.880+0000] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/operators/sql.py", line 274, in execute
    **extra_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 349, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 380, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.

[2025-02-27T16:20:02.886+0000] {taskinstance.py:1373} INFO - Marking task as FAILED. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T162002, end_date=20250227T162002
[2025-02-27T16:20:02.893+0000] {standard_task_runner.py:109} ERROR - Failed to execute job 2 for task create_station_informations_table (duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
; 180)
[2025-02-27T16:20:02.909+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 1
[2025-02-27T16:20:02.939+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T16:27:35.365+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:27:35.371+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:27:35.372+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T16:27:35.382+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T16:27:35.386+0000] {standard_task_runner.py:57} INFO - Started process 178 to run task
[2025-02-27T16:27:35.389+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpcuhxdpuf']
[2025-02-27T16:27:35.392+0000] {standard_task_runner.py:85} INFO - Job 2: Subtask create_station_informations_table
[2025-02-27T16:27:35.456+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 256910fe3a65
[2025-02-27T16:27:35.538+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T16:27:35.539+0000] {sql.py:262} INFO - Executing: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        
[2025-02-27T16:27:35.547+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T16:27:35.679+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T16:27:35.683+0000] {sql.py:375} INFO - Running statement: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        , parameters: None
[2025-02-27T16:27:35.708+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T162735, end_date=20250227T162735
[2025-02-27T16:27:35.736+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T16:27:35.771+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T16:34:49.858+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:34:49.863+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:34:49.863+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T16:34:49.871+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T16:34:49.877+0000] {standard_task_runner.py:57} INFO - Started process 177 to run task
[2025-02-27T16:34:49.879+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpwaac5dw9']
[2025-02-27T16:34:49.882+0000] {standard_task_runner.py:85} INFO - Job 3: Subtask create_station_informations_table
[2025-02-27T16:34:49.943+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 3392905e5c72
[2025-02-27T16:34:50.023+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T16:34:50.024+0000] {sql.py:262} INFO - Executing: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        
[2025-02-27T16:34:50.030+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T16:34:50.152+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T16:34:50.155+0000] {sql.py:375} INFO - Running statement: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        , parameters: None
[2025-02-27T16:34:50.167+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T163449, end_date=20250227T163450
[2025-02-27T16:34:50.183+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T16:34:50.240+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T16:42:12.361+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:42:12.366+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:42:12.366+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T16:42:12.374+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T16:42:12.376+0000] {standard_task_runner.py:57} INFO - Started process 179 to run task
[2025-02-27T16:42:12.379+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmput154dew']
[2025-02-27T16:42:12.381+0000] {standard_task_runner.py:85} INFO - Job 2: Subtask create_station_informations_table
[2025-02-27T16:42:12.438+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 0cb13b06ea45
[2025-02-27T16:42:12.511+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T16:42:12.511+0000] {sql.py:262} INFO - Executing: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        
[2025-02-27T16:42:12.517+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T16:42:12.632+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T16:42:12.635+0000] {sql.py:375} INFO - Running statement: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        , parameters: None
[2025-02-27T16:42:12.646+0000] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/operators/sql.py", line 274, in execute
    **extra_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 349, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 380, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.

[2025-02-27T16:42:12.661+0000] {taskinstance.py:1373} INFO - Marking task as FAILED. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T164212, end_date=20250227T164212
[2025-02-27T16:42:12.668+0000] {standard_task_runner.py:109} ERROR - Failed to execute job 2 for task create_station_informations_table (duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
; 179)
[2025-02-27T16:42:12.682+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 1
[2025-02-27T16:42:12.698+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T16:47:37.733+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:47:37.743+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:47:37.744+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T16:47:37.753+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T16:47:37.757+0000] {standard_task_runner.py:57} INFO - Started process 177 to run task
[2025-02-27T16:47:37.760+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmprd8cvegq']
[2025-02-27T16:47:37.762+0000] {standard_task_runner.py:85} INFO - Job 2: Subtask create_station_informations_table
[2025-02-27T16:47:37.817+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 357b585475c9
[2025-02-27T16:47:37.889+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T16:47:37.889+0000] {sql.py:262} INFO - Executing: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        
[2025-02-27T16:47:37.899+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T16:47:38.020+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T16:47:38.025+0000] {sql.py:375} INFO - Running statement: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        , parameters: None
[2025-02-27T16:47:38.030+0000] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/operators/sql.py", line 274, in execute
    **extra_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 349, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 380, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.

[2025-02-27T16:47:38.034+0000] {taskinstance.py:1373} INFO - Marking task as FAILED. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T164737, end_date=20250227T164738
[2025-02-27T16:47:38.042+0000] {standard_task_runner.py:109} ERROR - Failed to execute job 2 for task create_station_informations_table (duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
; 177)
[2025-02-27T16:47:38.066+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 1
[2025-02-27T16:47:38.084+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T16:53:41.320+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:53:41.325+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:53:41.325+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T16:53:41.334+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T16:53:41.338+0000] {standard_task_runner.py:57} INFO - Started process 177 to run task
[2025-02-27T16:53:41.353+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp4s5fs8h4']
[2025-02-27T16:53:41.356+0000] {standard_task_runner.py:85} INFO - Job 2: Subtask create_station_informations_table
[2025-02-27T16:53:41.403+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host a0bfba191c0c
[2025-02-27T16:53:41.471+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T16:53:41.471+0000] {sql.py:262} INFO - Executing: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        
[2025-02-27T16:53:41.483+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T16:53:41.612+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T16:53:41.616+0000] {sql.py:375} INFO - Running statement: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        , parameters: None
[2025-02-27T16:53:41.621+0000] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/operators/sql.py", line 274, in execute
    **extra_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 349, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 380, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.

[2025-02-27T16:53:41.626+0000] {taskinstance.py:1373} INFO - Marking task as FAILED. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T165341, end_date=20250227T165341
[2025-02-27T16:53:41.635+0000] {standard_task_runner.py:109} ERROR - Failed to execute job 2 for task create_station_informations_table (duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(velib_station_details, 2200) already exists.
; 177)
[2025-02-27T16:53:41.649+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 1
[2025-02-27T16:53:41.675+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T16:54:35.426+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:54:35.432+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:54:35.432+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T16:54:35.439+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T16:54:35.444+0000] {standard_task_runner.py:57} INFO - Started process 331 to run task
[2025-02-27T16:54:35.446+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '11', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp_antbyyp']
[2025-02-27T16:54:35.448+0000] {standard_task_runner.py:85} INFO - Job 11: Subtask create_station_informations_table
[2025-02-27T16:54:35.492+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host a0bfba191c0c
[2025-02-27T16:54:35.552+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T16:54:35.553+0000] {sql.py:262} INFO - Executing: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        
[2025-02-27T16:54:35.558+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T16:54:35.621+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T16:54:35.624+0000] {sql.py:375} INFO - Running statement: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        , parameters: None
[2025-02-27T16:54:35.631+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T165435, end_date=20250227T165435
[2025-02-27T16:54:35.671+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T16:54:35.689+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T16:55:05.811+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:55:05.816+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:55:05.816+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T16:55:05.824+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T16:55:05.827+0000] {standard_task_runner.py:57} INFO - Started process 480 to run task
[2025-02-27T16:55:05.829+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '19', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpsjxt9osz']
[2025-02-27T16:55:05.831+0000] {standard_task_runner.py:85} INFO - Job 19: Subtask create_station_informations_table
[2025-02-27T16:55:05.878+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host a0bfba191c0c
[2025-02-27T16:55:05.928+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T16:55:05.928+0000] {sql.py:262} INFO - Executing: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        
[2025-02-27T16:55:05.933+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T16:55:05.987+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T16:55:05.989+0000] {sql.py:375} INFO - Running statement: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        , parameters: None
[2025-02-27T16:55:05.995+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T165505, end_date=20250227T165505
[2025-02-27T16:55:06.011+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T16:55:06.038+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T17:12:09.257+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T17:12:09.262+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T17:12:09.262+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T17:12:09.271+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T17:12:09.275+0000] {standard_task_runner.py:57} INFO - Started process 177 to run task
[2025-02-27T17:12:09.278+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp0f130b1_']
[2025-02-27T17:12:09.281+0000] {standard_task_runner.py:85} INFO - Job 3: Subtask create_station_informations_table
[2025-02-27T17:12:09.337+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host f4e90ab2c82e
[2025-02-27T17:12:09.429+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T17:12:09.432+0000] {sql.py:262} INFO - Executing: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        
[2025-02-27T17:12:09.449+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T17:12:09.598+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T17:12:09.611+0000] {sql.py:375} INFO - Running statement: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        , parameters: None
[2025-02-27T17:12:09.626+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T171209, end_date=20250227T171209
[2025-02-27T17:12:09.664+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T17:12:09.692+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T17:21:46.664+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T17:21:46.669+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T17:21:46.669+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T17:21:46.680+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T17:21:46.686+0000] {standard_task_runner.py:57} INFO - Started process 179 to run task
[2025-02-27T17:21:46.689+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpz9zaag7m']
[2025-02-27T17:21:46.693+0000] {standard_task_runner.py:85} INFO - Job 2: Subtask create_station_informations_table
[2025-02-27T17:21:46.743+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host a103a973a33d
[2025-02-27T17:21:46.804+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T17:21:46.805+0000] {sql.py:262} INFO - Executing: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        
[2025-02-27T17:21:46.811+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T17:21:46.930+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T17:21:46.934+0000] {sql.py:375} INFO - Running statement: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        , parameters: None
[2025-02-27T17:21:46.948+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T172146, end_date=20250227T172146
[2025-02-27T17:21:46.992+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T17:21:47.022+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T17:27:25.050+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T17:27:25.058+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T17:27:25.058+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T17:27:25.076+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T17:27:25.086+0000] {standard_task_runner.py:57} INFO - Started process 178 to run task
[2025-02-27T17:27:25.091+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpsuu3fah7']
[2025-02-27T17:27:25.093+0000] {standard_task_runner.py:85} INFO - Job 2: Subtask create_station_informations_table
[2025-02-27T17:27:25.156+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 6787c35814a1
[2025-02-27T17:27:25.233+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T17:27:25.234+0000] {sql.py:262} INFO - Executing: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        
[2025-02-27T17:27:25.240+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T17:27:25.356+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T17:27:25.360+0000] {sql.py:375} INFO - Running statement: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        , parameters: None
[2025-02-27T17:27:25.377+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T172725, end_date=20250227T172725
[2025-02-27T17:27:25.436+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T17:27:25.468+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T19:14:27.541+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T19:14:27.547+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T19:14:27.548+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T19:14:27.555+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T19:14:27.560+0000] {standard_task_runner.py:57} INFO - Started process 1113 to run task
[2025-02-27T19:14:27.563+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '17', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpmsrwl12h']
[2025-02-27T19:14:27.565+0000] {standard_task_runner.py:85} INFO - Job 17: Subtask create_station_informations_table
[2025-02-27T19:14:27.638+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 6787c35814a1
[2025-02-27T19:14:27.720+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T19:14:27.721+0000] {sql.py:262} INFO - Executing: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        
[2025-02-27T19:14:27.729+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T19:14:27.775+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T19:14:27.777+0000] {sql.py:375} INFO - Running statement: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        , parameters: None
[2025-02-27T19:14:27.785+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T191427, end_date=20250227T191427
[2025-02-27T19:14:27.829+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T19:14:27.855+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T19:18:01.117+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T19:18:01.123+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T19:18:01.123+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T19:18:01.132+0000] {taskinstance.py:1350} INFO - Executing <Task(PostgresOperator): create_station_informations_table> on 2025-02-26 00:00:00+00:00
[2025-02-27T19:18:01.137+0000] {standard_task_runner.py:57} INFO - Started process 177 to run task
[2025-02-27T19:18:01.140+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'create_station_informations_table', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpodn701h2']
[2025-02-27T19:18:01.143+0000] {standard_task_runner.py:85} INFO - Job 3: Subtask create_station_informations_table
[2025-02-27T19:18:01.192+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.create_station_informations_table scheduled__2025-02-26T00:00:00+00:00 [running]> on host 4ff83f64f86f
[2025-02-27T19:18:01.270+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='create_station_informations_table' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T19:18:01.271+0000] {sql.py:262} INFO - Executing: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        
[2025-02-27T19:18:01.280+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T19:18:01.412+0000] {base.py:73} INFO - Using connection ID 'postgres_default' for task execution.
[2025-02-27T19:18:01.417+0000] {sql.py:375} INFO - Running statement: 
        
        CREATE TABLE IF NOT EXISTS public.velib_station_details (
                station_id BIGINT PRIMARY KEY,
                capacity INT,
                lat DOUBLE PRECISION,
                lon DOUBLE PRECISION,
                name VARCHAR(255)
            );

        , parameters: None
[2025-02-27T19:18:01.437+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=create_station_informations_table, execution_date=20250226T000000, start_date=20250227T191801, end_date=20250227T191801
[2025-02-27T19:18:01.483+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T19:18:01.504+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
