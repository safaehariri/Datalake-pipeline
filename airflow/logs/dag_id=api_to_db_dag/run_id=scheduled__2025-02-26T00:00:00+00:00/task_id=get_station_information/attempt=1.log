[2025-02-27T11:39:45.902+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T11:39:45.910+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T11:39:45.910+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T11:39:45.920+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T11:39:45.923+0000] {standard_task_runner.py:57} INFO - Started process 217 to run task
[2025-02-27T11:39:45.925+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp70edsswh']
[2025-02-27T11:39:45.928+0000] {standard_task_runner.py:85} INFO - Job 8: Subtask get_station_information
[2025-02-27T11:39:45.958+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host a00cf8e93560
[2025-02-27T11:39:46.011+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T11:39:46.011+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T11:39:46.016+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T11:39:46.301+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T113945, end_date=20250227T113946
[2025-02-27T11:39:46.312+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T11:39:46.329+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T11:59:48.329+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T11:59:48.339+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T11:59:48.341+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T11:59:48.356+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T11:59:48.363+0000] {standard_task_runner.py:57} INFO - Started process 313 to run task
[2025-02-27T11:59:48.370+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpyg704otb']
[2025-02-27T11:59:48.373+0000] {standard_task_runner.py:85} INFO - Job 8: Subtask get_station_information
[2025-02-27T11:59:48.451+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host 8e4c40b4e563
[2025-02-27T11:59:48.613+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T11:59:48.614+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T11:59:48.626+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T11:59:49.091+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T115948, end_date=20250227T115949
[2025-02-27T11:59:49.123+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T11:59:49.146+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T12:08:03.763+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T12:08:03.773+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T12:08:03.774+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T12:08:03.788+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T12:08:03.790+0000] {standard_task_runner.py:57} INFO - Started process 279 to run task
[2025-02-27T12:08:03.793+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmprc478c07']
[2025-02-27T12:08:03.795+0000] {standard_task_runner.py:85} INFO - Job 8: Subtask get_station_information
[2025-02-27T12:08:03.845+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host d2a66760e739
[2025-02-27T12:08:03.905+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T12:08:03.906+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T12:08:03.911+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T12:08:04.223+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T120803, end_date=20250227T120804
[2025-02-27T12:08:04.266+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T12:08:04.283+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T12:23:27.879+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T12:23:27.885+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T12:23:27.885+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T12:23:27.892+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T12:23:27.896+0000] {standard_task_runner.py:57} INFO - Started process 187 to run task
[2025-02-27T12:23:27.898+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp_sxr_f04']
[2025-02-27T12:23:27.900+0000] {standard_task_runner.py:85} INFO - Job 6: Subtask get_station_information
[2025-02-27T12:23:27.931+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host 0972c516a0af
[2025-02-27T12:23:27.986+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T12:23:27.986+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T12:23:27.991+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T12:23:28.209+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T122327, end_date=20250227T122328
[2025-02-27T12:23:28.242+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T12:23:28.256+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T13:16:20.972+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T13:16:20.982+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T13:16:20.982+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T13:16:20.996+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T13:16:20.999+0000] {standard_task_runner.py:57} INFO - Started process 214 to run task
[2025-02-27T13:16:21.001+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp7gqw4ffk']
[2025-02-27T13:16:21.002+0000] {standard_task_runner.py:85} INFO - Job 6: Subtask get_station_information
[2025-02-27T13:16:21.034+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host 3f89a3e69849
[2025-02-27T13:16:21.082+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T13:16:21.083+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T13:16:21.087+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T13:16:21.317+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T131620, end_date=20250227T131621
[2025-02-27T13:16:21.348+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T13:16:21.362+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T13:22:34.704+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T13:22:34.709+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T13:22:34.709+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T13:22:34.716+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T13:22:34.719+0000] {standard_task_runner.py:57} INFO - Started process 182 to run task
[2025-02-27T13:22:34.721+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp90wvkjwt']
[2025-02-27T13:22:34.722+0000] {standard_task_runner.py:85} INFO - Job 6: Subtask get_station_information
[2025-02-27T13:22:34.752+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host f51c37a32fa6
[2025-02-27T13:22:34.799+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T13:22:34.800+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T13:22:34.804+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T13:22:35.028+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T132234, end_date=20250227T132235
[2025-02-27T13:22:35.068+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T13:22:35.093+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T13:50:52.335+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T13:50:52.341+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T13:50:52.342+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T13:50:52.351+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T13:50:52.354+0000] {standard_task_runner.py:57} INFO - Started process 189 to run task
[2025-02-27T13:50:52.356+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpw8rm_tfz']
[2025-02-27T13:50:52.357+0000] {standard_task_runner.py:85} INFO - Job 7: Subtask get_station_information
[2025-02-27T13:50:52.384+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host 0dc2b4101260
[2025-02-27T13:50:52.430+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T13:50:52.430+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T13:50:52.435+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T13:50:52.646+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T135052, end_date=20250227T135052
[2025-02-27T13:50:52.661+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T13:50:52.674+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T13:58:14.328+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T13:58:14.336+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T13:58:14.336+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T13:58:14.344+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T13:58:14.347+0000] {standard_task_runner.py:57} INFO - Started process 193 to run task
[2025-02-27T13:58:14.348+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpyugnajf3']
[2025-02-27T13:58:14.350+0000] {standard_task_runner.py:85} INFO - Job 7: Subtask get_station_information
[2025-02-27T13:58:14.376+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host 90fb001151ab
[2025-02-27T13:58:14.420+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T13:58:14.421+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T13:58:14.426+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T13:58:14.617+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T135814, end_date=20250227T135814
[2025-02-27T13:58:14.650+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T13:58:14.664+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T14:03:46.249+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T14:03:46.255+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T14:03:46.256+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T14:03:46.264+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T14:03:46.267+0000] {standard_task_runner.py:57} INFO - Started process 191 to run task
[2025-02-27T14:03:46.269+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp0__kkokz']
[2025-02-27T14:03:46.270+0000] {standard_task_runner.py:85} INFO - Job 8: Subtask get_station_information
[2025-02-27T14:03:46.296+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host 5b8533a39e96
[2025-02-27T14:03:46.340+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T14:03:46.341+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T14:03:46.345+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T14:03:46.536+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T140346, end_date=20250227T140346
[2025-02-27T14:03:46.573+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T14:03:46.589+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T14:24:46.003+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T14:24:46.009+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T14:24:46.009+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T14:24:46.017+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T14:24:46.019+0000] {standard_task_runner.py:57} INFO - Started process 192 to run task
[2025-02-27T14:24:46.021+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmptjfmbrue']
[2025-02-27T14:24:46.022+0000] {standard_task_runner.py:85} INFO - Job 6: Subtask get_station_information
[2025-02-27T14:24:46.051+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host dc3a30e27f13
[2025-02-27T14:24:46.095+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T14:24:46.095+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T14:24:46.101+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T14:24:46.323+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T142446, end_date=20250227T142446
[2025-02-27T14:24:46.332+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T14:24:46.346+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T14:30:57.184+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T14:30:57.190+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T14:30:57.191+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T14:30:57.203+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T14:30:57.206+0000] {standard_task_runner.py:57} INFO - Started process 193 to run task
[2025-02-27T14:30:57.208+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp6p4pb081']
[2025-02-27T14:30:57.210+0000] {standard_task_runner.py:85} INFO - Job 8: Subtask get_station_information
[2025-02-27T14:30:57.246+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host a552db7362e5
[2025-02-27T14:30:57.314+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T14:30:57.315+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T14:30:57.321+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T14:30:57.498+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T143057, end_date=20250227T143057
[2025-02-27T14:30:57.549+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T14:30:57.581+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T14:51:51.174+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T14:51:51.179+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T14:51:51.180+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T14:51:51.187+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T14:51:51.191+0000] {standard_task_runner.py:57} INFO - Started process 282 to run task
[2025-02-27T14:51:51.193+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp32_6_uft']
[2025-02-27T14:51:51.194+0000] {standard_task_runner.py:85} INFO - Job 6: Subtask get_station_information
[2025-02-27T14:51:51.223+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host b6fe49d0fb59
[2025-02-27T14:51:51.270+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T14:51:51.272+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T14:51:51.277+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T14:51:51.502+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T145151, end_date=20250227T145151
[2025-02-27T14:51:51.540+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T14:51:51.575+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T15:50:25.150+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T15:50:25.155+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T15:50:25.155+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T15:50:25.163+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T15:50:25.167+0000] {standard_task_runner.py:57} INFO - Started process 188 to run task
[2025-02-27T15:50:25.168+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp8z4bpgx3']
[2025-02-27T15:50:25.170+0000] {standard_task_runner.py:85} INFO - Job 6: Subtask get_station_information
[2025-02-27T15:50:25.199+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host b95c8530fb6c
[2025-02-27T15:50:25.244+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T15:50:25.245+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T15:50:25.250+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T15:50:25.442+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T155025, end_date=20250227T155025
[2025-02-27T15:50:25.472+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T15:50:25.486+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T15:53:08.587+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T15:53:08.593+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T15:53:08.595+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T15:53:08.603+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T15:53:08.606+0000] {standard_task_runner.py:57} INFO - Started process 184 to run task
[2025-02-27T15:53:08.608+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmprajklr0f']
[2025-02-27T15:53:08.609+0000] {standard_task_runner.py:85} INFO - Job 7: Subtask get_station_information
[2025-02-27T15:53:08.639+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host f5aed095ee09
[2025-02-27T15:53:08.687+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T15:53:08.689+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T15:53:08.694+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T15:53:08.900+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T155308, end_date=20250227T155308
[2025-02-27T15:53:08.919+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T15:53:08.944+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T16:06:31.575+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:06:31.580+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:06:31.580+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T16:06:31.587+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T16:06:31.590+0000] {standard_task_runner.py:57} INFO - Started process 184 to run task
[2025-02-27T16:06:31.592+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpzxy6pon9']
[2025-02-27T16:06:31.593+0000] {standard_task_runner.py:85} INFO - Job 7: Subtask get_station_information
[2025-02-27T16:06:31.621+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host 70227d8e9381
[2025-02-27T16:06:31.671+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T16:06:31.671+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T16:06:31.676+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T16:06:31.933+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T160631, end_date=20250227T160631
[2025-02-27T16:06:31.980+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T16:06:31.998+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T16:27:36.656+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:27:36.662+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:27:36.662+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T16:27:36.670+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T16:27:36.673+0000] {standard_task_runner.py:57} INFO - Started process 184 to run task
[2025-02-27T16:27:36.674+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp_1p8j6kg']
[2025-02-27T16:27:36.676+0000] {standard_task_runner.py:85} INFO - Job 7: Subtask get_station_information
[2025-02-27T16:27:36.714+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host 256910fe3a65
[2025-02-27T16:27:36.762+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T16:27:36.762+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T16:27:36.767+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T16:27:36.949+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T162736, end_date=20250227T162736
[2025-02-27T16:27:36.983+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T16:27:36.997+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T16:34:51.321+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:34:51.328+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:34:51.329+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T16:34:51.336+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T16:34:51.339+0000] {standard_task_runner.py:57} INFO - Started process 182 to run task
[2025-02-27T16:34:51.341+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpv28ez_ej']
[2025-02-27T16:34:51.342+0000] {standard_task_runner.py:85} INFO - Job 6: Subtask get_station_information
[2025-02-27T16:34:51.370+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host 3392905e5c72
[2025-02-27T16:34:51.414+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T16:34:51.415+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T16:34:51.420+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T16:34:51.676+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T163451, end_date=20250227T163451
[2025-02-27T16:34:51.727+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T16:34:51.743+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T16:54:36.314+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:54:36.319+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:54:36.319+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T16:54:36.327+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T16:54:36.329+0000] {standard_task_runner.py:57} INFO - Started process 335 to run task
[2025-02-27T16:54:36.331+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '13', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmptv_2java']
[2025-02-27T16:54:36.332+0000] {standard_task_runner.py:85} INFO - Job 13: Subtask get_station_information
[2025-02-27T16:54:36.397+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host a0bfba191c0c
[2025-02-27T16:54:36.461+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T16:54:36.462+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T16:54:36.469+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T16:54:36.626+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T165436, end_date=20250227T165436
[2025-02-27T16:54:36.635+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T16:54:36.653+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T16:55:06.695+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:55:06.702+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T16:55:06.702+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T16:55:06.712+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T16:55:06.714+0000] {standard_task_runner.py:57} INFO - Started process 483 to run task
[2025-02-27T16:55:06.716+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '20', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpcr6furb7']
[2025-02-27T16:55:06.718+0000] {standard_task_runner.py:85} INFO - Job 20: Subtask get_station_information
[2025-02-27T16:55:06.752+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host a0bfba191c0c
[2025-02-27T16:55:06.800+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T16:55:06.801+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T16:55:06.808+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T16:55:07.003+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T165506, end_date=20250227T165507
[2025-02-27T16:55:07.022+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T16:55:07.039+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T17:12:10.244+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T17:12:10.250+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T17:12:10.250+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T17:12:10.258+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T17:12:10.262+0000] {standard_task_runner.py:57} INFO - Started process 184 to run task
[2025-02-27T17:12:10.264+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp4m3_l3k6']
[2025-02-27T17:12:10.265+0000] {standard_task_runner.py:85} INFO - Job 7: Subtask get_station_information
[2025-02-27T17:12:10.293+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host f4e90ab2c82e
[2025-02-27T17:12:10.339+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T17:12:10.339+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T17:12:10.344+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T17:12:10.559+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T171210, end_date=20250227T171210
[2025-02-27T17:12:10.609+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T17:12:10.623+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T17:21:47.426+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T17:21:47.432+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T17:21:47.433+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T17:21:47.442+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T17:21:47.448+0000] {standard_task_runner.py:57} INFO - Started process 183 to run task
[2025-02-27T17:21:47.450+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpn8a3rg5x']
[2025-02-27T17:21:47.451+0000] {standard_task_runner.py:85} INFO - Job 6: Subtask get_station_information
[2025-02-27T17:21:47.496+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host a103a973a33d
[2025-02-27T17:21:47.560+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T17:21:47.561+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T17:21:47.566+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T17:21:47.825+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T172147, end_date=20250227T172147
[2025-02-27T17:21:47.841+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T17:21:47.856+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T17:27:26.738+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T17:27:26.743+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T17:27:26.743+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T17:27:26.750+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T17:27:26.753+0000] {standard_task_runner.py:57} INFO - Started process 184 to run task
[2025-02-27T17:27:26.755+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpdk5s4bff']
[2025-02-27T17:27:26.756+0000] {standard_task_runner.py:85} INFO - Job 6: Subtask get_station_information
[2025-02-27T17:27:26.788+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host 6787c35814a1
[2025-02-27T17:27:26.836+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T17:27:26.837+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T17:27:26.842+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T17:27:27.028+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T172726, end_date=20250227T172727
[2025-02-27T17:27:27.059+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T17:27:27.075+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T19:14:28.321+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T19:14:28.326+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T19:14:28.326+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T19:14:28.333+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T19:14:28.336+0000] {standard_task_runner.py:57} INFO - Started process 1123 to run task
[2025-02-27T19:14:28.339+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '23', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmptd8hzfr0']
[2025-02-27T19:14:28.340+0000] {standard_task_runner.py:85} INFO - Job 23: Subtask get_station_information
[2025-02-27T19:14:28.393+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host 6787c35814a1
[2025-02-27T19:14:28.445+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T19:14:28.446+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T19:14:28.452+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T19:14:28.689+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T191428, end_date=20250227T191428
[2025-02-27T19:14:28.726+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T19:14:28.748+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T19:18:01.968+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T19:18:01.973+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T19:18:01.974+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T19:18:01.981+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T19:18:01.983+0000] {standard_task_runner.py:57} INFO - Started process 184 to run task
[2025-02-27T19:18:01.985+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpe4tzpukq']
[2025-02-27T19:18:01.987+0000] {standard_task_runner.py:85} INFO - Job 7: Subtask get_station_information
[2025-02-27T19:18:02.018+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host 4ff83f64f86f
[2025-02-27T19:18:02.072+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T19:18:02.072+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T19:18:02.077+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T19:18:02.294+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T191801, end_date=20250227T191802
[2025-02-27T19:18:02.331+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T19:18:02.375+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T20:55:21.367+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T20:55:21.375+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T20:55:21.375+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T20:55:21.386+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T20:55:21.397+0000] {standard_task_runner.py:57} INFO - Started process 271 to run task
[2025-02-27T20:55:21.410+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpqdhugg8z']
[2025-02-27T20:55:21.413+0000] {standard_task_runner.py:85} INFO - Job 7: Subtask get_station_information
[2025-02-27T20:55:21.496+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host 53fdc8261bae
[2025-02-27T20:55:21.970+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T20:55:21.972+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T20:55:21.996+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T20:55:22.187+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T205521, end_date=20250227T205522
[2025-02-27T20:55:22.245+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T20:55:22.272+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-02-27T23:34:25.037+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T23:34:25.066+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [queued]>
[2025-02-27T23:34:25.067+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2025-02-27T23:34:25.090+0000] {taskinstance.py:1350} INFO - Executing <Task(SimpleHttpOperator): get_station_information> on 2025-02-26 00:00:00+00:00
[2025-02-27T23:34:25.112+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-02-27T23:34:25.110+0000] {standard_task_runner.py:57} INFO - Started process 1163 to run task
[2025-02-27T23:34:25.133+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'api_to_db_dag', 'get_station_information', 'scheduled__2025-02-26T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp46fzwsa7']
[2025-02-27T23:34:25.137+0000] {standard_task_runner.py:85} INFO - Job 3: Subtask get_station_information
[2025-02-27T23:34:25.214+0000] {task_command.py:410} INFO - Running <TaskInstance: api_to_db_dag.get_station_information scheduled__2025-02-26T00:00:00+00:00 [running]> on host 80b2b1669f52
[2025-02-27T23:34:25.221+0000] {clientserver.py:505} INFO - Error while sending or receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 503, in send_command
    self.socket.sendall(command.encode("utf-8"))
ConnectionResetError: [Errno 104] Connection reset by peer
[2025-02-27T23:34:25.233+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-02-27T23:34:25.236+0000] {java_gateway.py:1052} INFO - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 503, in send_command
    self.socket.sendall(command.encode("utf-8"))
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 507, in send_command
    "Error while sending", e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending
[2025-02-27T23:34:25.247+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-02-27T23:34:25.353+0000] {taskinstance.py:1570} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='api_to_db_dag' AIRFLOW_CTX_TASK_ID='get_station_information' AIRFLOW_CTX_EXECUTION_DATE='2025-02-26T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-02-26T00:00:00+00:00'
[2025-02-27T23:34:25.354+0000] {http.py:123} INFO - Calling HTTP method
[2025-02-27T23:34:25.363+0000] {base.py:73} INFO - Using connection ID 'velib_api_connection' for task execution.
[2025-02-27T23:34:25.562+0000] {taskinstance.py:1373} INFO - Marking task as SUCCESS. dag_id=api_to_db_dag, task_id=get_station_information, execution_date=20250226T000000, start_date=20250227T233425, end_date=20250227T233425
[2025-02-27T23:34:25.591+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2025-02-27T23:34:25.614+0000] {taskinstance.py:2674} INFO - 1 downstream tasks scheduled from follow-on schedule check
