services:
  ### ðŸŒ€ Airflow
  

  ### ðŸ—„ PostgreSQL (Base de donnÃ©es pour VÃ©lib' & DBT)
  postgres:
    image: postgres:13
    container_name: postgres
    restart: always
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    volumes:
      - pg_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 5s
      retries: 5
      start_period: 10s
    networks:
    - spark-network


  ### ðŸ”Ž Elasticsearch (Stocke les prÃ©dictions pour Kibana)
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.17.2
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=false
      - network.host=0.0.0.0
    volumes:
      - ./es_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - spark-network

  ### ðŸ“ˆ Kibana (Visualisation des prÃ©dictions)
  kibana:
    image: docker.elastic.co/kibana/kibana:8.17.2
    platform: linux/arm64
    container_name: kibana
    depends_on:
      - elasticsearch
    ports:
      - "5601:5601"
    networks:
    - spark-network
    volumes:
      - ./kibana_data:/usr/share/kibana/data


  airflow-webserver:
    image: my-airflow:2.6.0
    container_name: airflow-webserver
    restart: always
    depends_on:
      - postgres
    environment:
      - PYTHONPATH=/opt/airflow/
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - _AIRFLOW_WWW_USER_USERNAME=admin 
      - _AIRFLOW_WWW_USER_PASSWORD=admin 
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/lib:/opt/airflow/lib 
      - ./scripts/entrypoint.sh:/opt/airflow/entrypoint.sh
      - ./datalake:/mnt/data
    ports:
      - "8080:8080"

    command: ["bash", "/opt/airflow/entrypoint.sh"]
    networks:
    - spark-network

    
  airflow-scheduler:
    image: my-airflow:2.6.0
    container_name: airflow-scheduler
    restart: always
    depends_on:
      - postgres
    environment:
      - PYTHONPATH=/opt/airflow 
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/lib:/opt/airflow/lib 
      - ./airflow/logs:/opt/airflow/logs
      - ./datalake:/mnt/data

    command: ["airflow", "scheduler"]
    networks:
    - spark-network
   
  ### ðŸš€ Spark Cluster
  spark-master:
    image: my-spark-image 
    container_name: spark-master
    platform: linux/arm64
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - "7077:7077"  
      - "8081:8080" 
    networks:
      - spark-network
    volumes:
      - ./datalake:/mnt/data

  spark-worker:
    image: my-spark-image
    container_name: spark-worker
    platform: linux/arm64
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=4G
      - SPARK_WORKER_CORES=4
    depends_on:
      - spark-master
    networks:
      - spark-network
    volumes:
      - ./datalake:/mnt/data
    mem_limit: 6G

networks:
  spark-network:

volumes:
  pg_data:
  datalake:
  es_data:
  kibana_data: